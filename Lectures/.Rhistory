pBeta1 <- 2 * pt(abs(tBeta1), df = n - 2, lower.tail = FALSE)
pBeta0
pBeta1
coefTable <- rbind(c(beta0, seBeta0, tBeta0, pBeta0), c(beta1, seBeta1, tBeta1, pBeta1))
colnames(coefTable) <- c("Estimate", "Std. Error", "t value", "P(>|t|)")
rownames(coefTable) <- c("(Intercept)", "x")
coefTable
fit <- lm(y ~ x);
summary(fit)$coefficients
pBeta0 <- 2 * pt(abs(tBeta0), df = n - 2, lower.tail = FALSE)
pBeta1 <- 2 * pt(abs(tBeta1), df = n - 2, lower.tail = FALSE)
coefTable <- rbind(c(beta0, seBeta0, tBeta0, pBeta0), c(beta1, seBeta1, tBeta1, pBeta1))
colnames(coefTable) <- c("Estimate", "Std. Error", "t value", "P(>|t|)")
rownames(coefTable) <- c("(Intercept)", "x")
coefTable
fit <- lm(y ~ x);
summary(fit)$coefficients
fit <- lm(y ~ x);
summary(fit)$coefficients
library(ggplot2)
newx = data.frame(x = seq(min(x), max(x), length = 100))
p1 = data.frame(predict(fit, newdata= newx,interval = ("confidence")))
p2 = data.frame(predict(fit, newdata = newx,interval = ("prediction")))
p1$interval = "confidence"
p2$interval = "prediction"
p1$x = newx$x
p2$x = newx$x
dat = rbind(p1, p2)
names(dat)[1] = "y"
g = ggplot(dat, aes(x = x, y = y))
g = g + geom_ribbon(aes(ymin = lwr, ymax = upr, fill = interval), alpha = 0.2)
g = g + geom_line()
g = g + geom_point(data = data.frame(x = x, y=y), aes(x = x, y = y), size = 4)
g
library(ggplot2)
newx = data.frame(x = seq(min(x), max(x), length = 100))
p1 = data.frame(predict(fit, newdata= newx,interval = ("confidence")))
p2 = data.frame(predict(fit, newdata = newx,interval = ("prediction")))
p1$interval = "confidence"
p2$interval = "prediction"
p1$x = newx$x
p2$x = newx$x
dat = rbind(p1, p2)
names(dat)[1] = "y"
g = ggplot(dat, aes(x = x, y = y))
g = g + geom_ribbon(aes(ymin = lwr, ymax = upr, fill = interval), alpha = 0.2)
g = g + geom_line()
g = g + geom_point(data = data.frame(x = x, y=y), aes(x = x, y = y), size = 4)
g
library(ggplot2)
newx = data.frame(x = seq(min(x), max(x), length = 100))
p1 = data.frame(predict(fit, newdata= newx,interval = ("confidence")))
p2 = data.frame(predict(fit, newdata = newx,interval = ("prediction")))
p1$interval = "confidence"
p2$interval = "prediction"
p1$x = newx$x
p2$x = newx$x
dat = rbind(p1, p2)
names(dat)[1] = "y"
g = ggplot(dat, aes(x = x, y = y))
g = g + geom_ribbon(aes(ymin = lwr, ymax = upr, fill = interval), alpha = 0.2)
g = g + geom_line()
g = g + geom_point(data = data.frame(x = x, y=y), aes(x = x, y = y), size = 4)
g
library(ggplot2)
newx = data.frame(x = seq(min(x), max(x), length = 100))
p1 = data.frame(predict(fit, newdata= newx,interval = ("confidence")))
p2 = data.frame(predict(fit, newdata = newx,interval = ("prediction")))
p1$interval = "confidence"
p2$interval = "prediction"
p1$x = newx$x
p2$x = newx$x
dat = rbind(p1, p2)
names(dat)[1] = "y"
g = ggplot(dat, aes(x = x, y = y))
g = g + geom_ribbon(aes(ymin = lwr, ymax = upr, fill = interval), alpha = 0.2)
g = g + geom_line()
g = g + geom_point(data = data.frame(x = x, y=y), aes(x = x, y = y), size = 4)
g
require(datasets); data(swiss); ?swiss
install.packages("GGally")
library(datasets); data(swiss); require(stats); require(graphics)
pairs(swiss, panel = panel.smooth, main = "Swiss data", col = 3 + (swiss$Catholic > 50))
summary(lm(Fertility ~ . , data = swiss))
pairs(swiss, panel = panel.smooth, main = "Swiss data", col = 3 + (swiss$Catholic > 50))
require(datasets)
data(swiss)
pairs(swiss, panel = panel.smooth, main = "Swiss data", col = 3 + (swiss$Catholic > 50))
summary(lm(Fertility ~ . , data = swiss))
summary(lm(Fertility ~ . , data = swiss))
summary(lm(Fertility ~ Agriculture, data = swiss))$coefficients
z <- swiss$Agriculture + swiss$Education
lm(Fertility ~ . + z, data = swiss)
##Dummy variables
require(datasets);data(InsectSprays); require(stats); require(ggplot2)
summary(lm(count ~ spray, data = InsectSprays))$coef
##Dummy variables
require(datasets);data(InsectSprays); require(stats); require(ggplot2)
summary(lm(count ~ spray, data = InsectSprays))$coef
summary(lm(count ~
I(1 * (spray == 'B')) + I(1 * (spray == 'C')) +
I(1 * (spray == 'D')) + I(1 * (spray == 'E')) +
I(1 * (spray == 'F')) + I(1 * (spray == 'A')), data = InsectSprays))$coef
summary(lm(count ~
I(1 * (spray == 'B')) + I(1 * (spray == 'C')) +
I(1 * (spray == 'D')) + I(1 * (spray == 'E')) +
I(1 * (spray == 'F')) + I(1 * (spray == 'A')), data = InsectSprays))$coef
spray2 <- relevel(InsectSprays$spray, "C")
summary(lm(count ~ spray2, data = InsectSprays))$coef
spray2 <- relevel(InsectSprays$spray, "C")
summary(lm(count ~ spray2, data = InsectSprays))$coef
fit1<-lm(Fertility~Agriculture,data=swiss)
fit3 <- update(fit1, Fertility ~ Agriculture + Examination + Education, data=swiss)
fit5 <- update(fit1, Fertility ~ Agriculture + Examination + Education + Catholic + Infant.Mortality, data=swiss)
anova(fit1, fit3, fit5)
setwd("/Users/diegorodrigues/Desktop/IP2022/IP2022/Lectures")
load("ravensData.rda")
head(ravensData)
lmRavens <- lm(ravensData$ravenWinNum ~ ravensData$ravenScore)
summary(lmRavens)$coef
## Consider setting b0 to 0 and varying b1
x = seq(-10, 10, length = 1000)
beta0 = 0; beta1s = seq(.25, 1.5, by = .1)
plot(c(-10, 10), c(0, 1), type = "n", xlab = "X", ylab = "Probability", frame = FALSE)
sapply(beta1s, function(beta1) {
y = 1 / (1 + exp( -1 * ( beta0 + beta1 * x ) ))
lines(x, y, type = "l", lwd = 3)
}
)
## Consider setting b1 and varying b0
x = seq(-10, 10, length = 1000)
beta0s = seq(-2, 2, by = .5); beta1 = 1
plot(c(-10, 10), c(0, 1), type = "n", xlab = "X", ylab = "Probability", frame = FALSE)
sapply(beta0s, function(beta0) {
y = 1 / (1 + exp( -1 * ( beta0 + beta1 * x ) ))
lines(x, y, type = "l", lwd = 3)
}
)
x = seq(-10, 10, length = 1000)
beta0 = 0; beta1 = 1
p = 1 / (1 + exp(-1 * (beta0 + beta1 * x)))
y = rbinom(prob = p, size = 1, n = length(p))
plot(x, y, frame = FALSE, xlab = "x", ylab = "y")
lines(lowess(x, y), type = "l", col = "blue", lwd = 3)
fit = glm(y ~ x, family = binomial)
lines(x, predict(fit, type = "response"), lwd = 3, col = "red")
y = rbinom(prob = p, size = 1, n = length(p))
plot(y)
plot(x, y, frame = FALSE, xlab = "x", ylab = "y")
lines(lowess(x, y), type = "l", col = "blue", lwd = 3)
fit = glm(y ~ x, family = binomial)
x = seq(-10, 10, length = 1000)
beta0 = 0; beta1 = 1
p = 1 / (1 + exp(-1 * (beta0 + beta1 * x)))
y = rbinom(prob = p, size = 1, n = length(p))
plot(x, y, frame = FALSE, xlab = "x", ylab = "y")
lines(lowess(x, y), type = "l", col = "blue", lwd = 3)
fit = glm(y ~ x, family = binomial)
lines(x, predict(fit, type = "response"), lwd = 3, col = "red")
lines(x,p, col ='green')
logRegRavens = glm(ravensData$ravenWinNum ~ ravensData$ravenScore,family="binomial")
summary(logRegRavens)
## plotting the fit
plot(ravensData$ravenScore,logRegRavens$fitted,pch=19,col="blue",xlab="Score",ylab="Prob Ravens Win")
plot(ravensData$ravenScore,logRegRavens$fitted,pch=19,col="blue",xlab="Score",ylab="Prob Ravens Win")
exp(logRegRavens$coeff)
exp(confint(logRegRavens))
## The first line of code shows that the exponentiated slope coefficient is 1.11. Thus, we estimate a 11%
## increase in the odds of winning per 1 point increase in score.
## Anova for logistic regression
anova(logRegRavens,test="Chisq")
install.packages("devtools")
library(devtools)
anova(logRegRavens,test="Chisq")
install.packages("devtools")
library(devtools)
install.packages("devtools")
require(foreign)
grogger <- read.dta("grogger.dta")
View(grogger)
lm1 = lm(grogger$avgsen ~ grogger$durat)
round(exp(coef(lm(I(log(grogger$avgsen + 1)) ~ grogger$durat))), 5)
glm1 = glm(grogger$avgsen ~ grogger$durat,family="poisson")
abline(lm1,col="red",lwd=3); lines(grogger$durat,glm1$fitted,col="blue",lwd=3)
glm1 = glm(grogger$avgsen ~ grogger$durat,family="poisson")
glm1
## Mean- variance relationship
plot(glm1$fitted,glm1$residuals,pch=19,col="grey",ylab="Residuals",xlab="Fitted")
glm2 = glm(grogger$avgsen ~ grogger$durat,family="quasipoisson", data = grogger)
## We can use the quasi-poisson when the mean-variance relationship is not observed
plot(glm1$fitted,glm1$residuals,pch=19,col="grey",ylab="Residuals",xlab="Fitted")
glm2 = glm(grogger$avgsen ~ grogger$durat,family="quasipoisson", data = grogger)
glm2
# Confidence interval expressed as a percentage
100 * (exp(confint(glm2)) - 1)[2,]
# As compared to the standard Poisson interval
100 * (exp(confint(glm1)) - 1)[2,]
library(UsingR)
data(mtcars)
mtcars
View(mtcars)
help(mtcars)
help(mtcars)
y = mtcars$mpg
x = cbind(1, mtcars$hp, mtcars$wt)
solve(t(x) %*% x) %*% t(x) %*% y
y = mtcars$mpg
x = cbind(1, mtcars$hp, mtcars$wt)
solve(t(x) %*% x) %*% t(x) %*% y
coef(lm(y~mtcars$hp+mtcars$wt,data=mtcars))
## Centering the data and taking the averages
n = nrow(x)
I = diag(rep(1, n))
H = matrix(1, n, n) / n
xt = (I - H) %*% x
apply(xt, 2, mean)
## Doing it using sweep
xt2 = sweep(x, 2, apply(x, 2, mean))
apply(xt2, 2, mean)
j <- cbind(rep(1,n))
xt = (I - j %*% solve(t(j) %*% j) %*% t(j)) %*% x
apply(xt, 2, mean)
## xt is the centered data of X
## yhat - y =x(x?x)^(-1)x?y
yhat <- x %*% solve(t(x) %*% x) %*% t(x) %*% y
e <- (I - x %*% solve(t(x) %*% x) %*% t(x) ) %*% y
e
residuals(lm(y~mtcars$hp+mtcars$wt,data=mtcars))
install.packages("rvest")
install.packages("tidyverse")
library("rvest")
library("tidyverse")
url = 'https://www.lemonde.fr/'
webpage = read_html(url) ##Reading the HTML code from the website
# Get the value of the accurate markup:
title = html_nodes(webpage, '.old__top-article .article__title')
real_title = html_text(title)
real_title
title = html_nodes(webpage, '.old__top-article .article__title')
title
real_title = html_text(title)
real_title
# Exercice 1: NYT
url = 'https://www.nytimes.com/'
webpage = read_html(url)
title = html_nodes(webpage, '.css-j7dc1m')
real_title = html_text(title)
real_title
# Exercice 1: NYT
url = 'https://www.nytimes.com/'
webpage = read_html(url)
title = html_nodes(webpage, '.css-1yxzums')
real_title = html_text(title)
real_title
url <- 'https://www.imdb.com/search/title/?title_type=feature&release_date=1998-01-01,1998-12-31&sort=boxoffice_gross_us,desc'
#Reading the HTML code from the website
webpage <- read_html(url)
rank_html <- html_nodes(webpage,'.text-primary')
rank <- html_text(rank_html)
rank
#Let's have a look at the rankings
head(rank)
# Convert into numeric data:
rank = as.numeric(rank)
### Do the same with the titles and the runtime
# Same for title
title_html <- html_nodes(webpage,'.lister-item-header a')
#Converting the title data to text
title <- html_text(title_html)
head(title)
title
#Using CSS selectors to scrape the Movie runtime section
runtime_html <- html_nodes(webpage,'.runtime')
#Converting the runtime data to text
runtime <- html_text(runtime_html)
#Let's have a look at the runtime
head(runtime)
runtime
#Data-Preprocessing: removing mins and converting it to numerical
runtime<-gsub(" min","",runtime)
runtime<-as.numeric(runtime)
runtime
#Let's have another look at the runtime data
head(runtime)
#Using CSS selectors to scrape the Movie genre section
genre_html <- html_nodes(webpage,'.genre')
#Converting the genre data to text
genre <- html_text(genre_html)
#Let's have a look at the runtime
head(genre)
#Data-Preprocessing: removing \n
genre<-gsub("\n","",genre)
genre
genre<-gsub(" ","",genre)
genre
genre<-gsub(",.*","",genre)
genre<-as.factor(genre)
genre
head(genre)
rating_html <- html_nodes(webpage,'.ratings-imdb-rating strong')
#Converting the ratings data to text
rating <- html_text(rating_html)
#Let's have a look at the ratings
head(rating)
#Data-Preprocessing: converting ratings to numerical
rating<-as.numeric(rating)
#Let's have another look at the ratings data
head(rating)
length(rating)
#Using CSS selectors to scrape the metascore section
metascore_html <- html_nodes(webpage,'.metascore')
#Converting the runtime data to text
metascore <- html_text(metascore_html)
#Let's have a look at the metascore
head(metascore)
metascore_data<-gsub(" ","",metascore)
#Using CSS selectors to scrape the gross revenue section
gross_html <- html_nodes(webpage,'.ghost~ .text-muted+ span')
#Converting the gross revenue data to text
gross <- html_text(gross_html)
#Let's have a look at the votes data
head(gross)
#Data-Preprocessing: removing '$' and 'M' signs
gross<-gsub("M","",gross)
gross<-substring(gross,2,6)
gross
gross = as.numeric(gross)
#Let's check the length of gross data
length(gross)
gross
#Combining all the lists to form a data frame
movies_df<-data.frame(Rank = rank,
Runtime = runtime,
Genre = genre, Rating = rating,
Revenue = gross)
str(movies_df)
library('ggplot2')
qplot(data = movies_df,Runtime,fill = Genre,bins = 30)
ggplot(movies_df,aes(x=Runtime,y=Rating))+
geom_point(aes(size=Revenue,col=Genre))
ggplot(movies_df,aes(x=Rank,y=Revenue))+ geom_point(aes(col=Genre))
ggplot(movies_df,aes(x=Revenue,y=Rating))+ geom_point(aes(col=Genre))
movie_revenue = lm(Revenue ~ Rating + Genre + Runtime, data =movies_df)
summary(movie_revenue)
View(ravensData)
View(ravensData)
setwd("/Users/diegorodrigues/Desktop/IP2022/IP2022/Lectures")
load("ravensData.rda")
head(ravensData)
lmRavens <- lm(ravensData$ravenWinNum ~ ravensData$ravenScore)
summary(lmRavens)$coef
lmRavens$coef[2]
lmRavens$coef[2]*70
sapply(1:5, function(num) num ^ 3)
x
## Consider setting b0 to 0 and varying b1
x = seq(-10, 10, length = 1000)
x
y=seq(-16,100, length =1000)
plot(x,y)
lines(x,y)
x = seq(-10, 10, length = 1000)
y =seq(1,100, length=1000)
z= y^2
x = seq(-10, 10, length = 1000)
y =seq(1,100, length=1000)
z= y^2
plot(x,y)
lines(x,z)
x = seq(-10, 10, length = 1000)
y =seq(1,100, length=1000)
z= x^2
plot(x,y)
lines(x,z)
x = seq(-10, 10, length = 1000)
beta0 = 0; beta1s = seq(.25, 1.5, by = .1)
lenght(beta1s)
length(beta1s)
x = seq(-10, 10, length = 1000)
beta0 = 0; beta1s = seq(.25, 1.5, by = .1)
length(beta1s)
sapply(beta1s, function(beta1) {
y = 1 / (1 + exp( -1 * ( beta0 + beta1 * x ) ))
lines(x, y, type = "l", lwd = 3)
}
)
y
x = seq(-10, 10, length = 1000)
beta0 = 0; beta1s = seq(.25, 1.5, by = .1)
plot(c(-10, 10), c(0, 1), type = "n", xlab = "X", ylab = "Probability", frame = FALSE)
sapply(beta1s, function(beta1) {
y = 1 / (1 + exp( -1 * ( beta0 + beta1 * x ) ))
lines(x, y, type = "l", lwd = 3)
}
)
## Consider setting b0 to 0 and varying b1
x = seq(-10, 10, length = 1000)
beta0 = 0; beta1s = seq(.25, 1.5, by = .1)
plot(c(-10, 10), c(0, 1), type = "n", xlab = "X", ylab = "Probability", frame = FALSE)
sapply(beta1s, function(beta1) {
y = 1 / (1 + exp( -1 * ( beta0 + beta1 * x ) ))
lines(x, y, type = "l", lwd = 3)
}
)
x = seq(-10, 10, length = 1000)
beta0 = 0; beta1s = seq(.25, 1.5, by = .1)
plot(c(-10, 10), c(0, 1), type = "n", xlab = "X", ylab = "Probability", frame = FALSE)
sapply(beta1s, function(beta1) {
y = 1 / (1 + exp( -1 * ( beta0 + beta1 * x ) ))
lines(x, y, type = "l", lwd = 3)
}
)
x = seq(-10, 10, length = 1000)
beta0 = 0; beta1 = 1
p = 1 / (1 + exp(-1 * (beta0 + beta1 * x)))
y = rbinom(prob = p, size = 1, n = length(p))
plot(x, y, frame = FALSE, xlab = "x", ylab = "y")
lines(lowess(x, y), type = "l", col = "blue", lwd = 3)
fit = glm(y ~ x, family = binomial)
fit
lines(x, predict(fit, type = "response"), lwd = 3, col = "red")
lines(lowess(x, y))
lines(x, predict(fit, type = "response"), lwd = 3, col = "red")
lines(x,p)
x = seq(-10, 10, length = 1000)
beta0 = 0; beta1 = 1
p = 1 / (1 + exp(-1 * (beta0 + beta1 * x)))
y = rbinom(prob = p, size = 1, n = length(p))
plot(x, y, frame = FALSE, xlab = "x", ylab = "y")
lines(lowess(x, y), type = "l", col = "blue", lwd = 3)
fit = glm(y ~ x, family = binomial)
lines(x, predict(fit, type = "response"), lwd = 3, col = "red")
lines(x,p, lwd = 3, col = "green")
logRegRavens = glm(ravensData$ravenWinNum ~ ravensData$ravenScore,family="binomial")
summary(logRegRavens)
## plotting the fit
plot(ravensData$ravenScore,logRegRavens$fitted,pch=19,col="blue",xlab="Score",ylab="Prob Ravens Win")
exp(logRegRavens$coeff)
plot(ravensData$ravenScore,logRegRavens$fitted,pch=19,col="blue",xlab="Score",ylab="Prob Ravens Win")
exp(logRegRavens$coeff)
anova(logRegRavens,test="Chisq")
install.packages("devtools")
library(devtools)
install.packages("devtools")
View(grogger)
help(grogger)
lm1 = lm(grogger$avgsen ~ grogger$durat)
lm1
round(exp(coef(lm(I(log(grogger$avgsen + 1)) ~ grogger$durat))), 5)
glm1 = glm(grogger$avgsen ~ grogger$durat,family="poisson")
glm1 = glm(grogger$avgsen ~ grogger$durat,family="poisson")
abline(lm1,col="red",lwd=3); lines(grogger$durat,glm1$fitted,col="blue",lwd=3)
glm1 = glm(grogger$avgsen ~ grogger$durat,family="poisson")
abline(lm1,col="red",lwd=3); lines(grogger$durat,glm1$fitted,col="blue",lwd=3)
## Mean- variance relationship
plot(glm1$fitted,glm1$residuals,pch=19,col="grey",ylab="Residuals",xlab="Fitted")
library(UsingR)
data(mtcars)
help(mtcars)
## Mean- variance relationship
plot(glm1$fitted,glm1$residuals,pch=19,col="grey",ylab="Residuals",xlab="Fitted")
y = mtcars$mpg
x = cbind(1, mtcars$hp, mtcars$wt)
solve(t(x) %*% x) %*% t(x) %*% y
y = mtcars$mpg
x = cbind(1, mtcars$hp, mtcars$wt)
solve(t(x) %*% x) %*% t(x) %*% y
coef(lm(y~mtcars$hp+mtcars$wt,data=mtcars))
e <- (I - x %*% solve(t(x) %*% x) %*% t(x) ) %*% y
install.packages("rvest")
install.packages("tidyverse")
library("rvest")
library("tidyverse")
###################################################
###################################################
# First exemple: lemonde.fr
url = 'https://www.lemonde.fr/'
install.packages("tidyverse")
install.packages("rvest")
url = 'https://www.lemonde.fr/'
webpage = read_html(url) ##Reading the HTML code from the website
# Get the value of the accurate markup:
title = html_nodes(webpage, '.old__top-article .article__title')
real_title = html_text(title)
real_title
# Exercice 1: NYT
url = 'https://www.nytimes.com/'
webpage = read_html(url)
title = html_nodes(webpage, '.css-1yxzums')
real_title = html_text(title)
real_title
url = 'https://www.nytimes.com/'
webpage = read_html(url)
title = html_nodes(webpage, '.css-1yxzums')
real_title = html_text(title)
real_title
#Specifying the url for desired website to be scraped
url <- 'https://www.imdb.com/search/title/?title_type=feature&release_date=1998-01-01,1998-12-31&sort=boxoffice_gross_us,desc'
##Send the website to the students
#Reading the HTML code from the website
webpage <- read_html(url)
webpage <- read_html(url)
rank_html <- html_nodes(webpage,'.text-primary')
rank <- html_text(rank_html)
#Let's have a look at the rankings
head(rank)
### Do the same with the titles and the runtime
# Same for title
title_html <- html_nodes(webpage,'.lister-item-header a')
#Converting the title data to text
title <- html_text(title_html)
head(title)
